{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39228,"status":"ok","timestamp":1712991748411,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"7i0VhXZ0oyNb","outputId":"3624b0ee-9c22-49c8-deec-9f8e118353a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzXrmfQIoz85","outputId":"cc27e235-8e0e-4498-db1a-82c01a2d5fab","executionInfo":{"status":"ok","timestamp":1712991977292,"user_tz":-300,"elapsed":228889,"user":{"displayName":"M Faizan","userId":"01979528019072830709"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1iS6gSWfUE3cZnmrNWbbV9_W_zQH3vaiu/enz-eff-project\n","Collecting pandas<1.6,>=1.4 (from -r requirements.txt (line 1))\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.25.2)\n","Collecting rdkit (from -r requirements.txt (line 4))\n","  Downloading rdkit-2023.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fair-esm (from -r requirements.txt (line 5))\n","  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.0.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.2.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.2.2)\n","Collecting pickle5 (from -r requirements.txt (line 10))\n","  Downloading pickle5-0.0.11.tar.gz (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting biopython (from -r requirements.txt (line 11))\n","  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2023.12.25)\n","Collecting drfp (from -r requirements.txt (line 13))\n","  Downloading drfp-0.3.6-py2.py3-none-any.whl (9.4 kB)\n","Collecting zeep (from -r requirements.txt (line 14))\n","  Downloading zeep-4.2.1-py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.2/101.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cobra (from -r requirements.txt (line 15))\n","  Downloading cobra-0.29.0-py2.py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pubchempy (from -r requirements.txt (line 16))\n","  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting suds (from -r requirements.txt (line 17))\n","  Downloading suds-1.1.2-py3-none-any.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bioservices (from -r requirements.txt (line 18))\n","  Downloading bioservices-1.11.2.tar.gz (191 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.9/191.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaleido (from -r requirements.txt (line 20))\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-multipart (from -r requirements.txt (line 21))\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Collecting uvicorn (from -r requirements.txt (line 22))\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions<4.6.0 (from -r requirements.txt (line 23))\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4->-r requirements.txt (line 1)) (2023.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.4)\n","INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n","Collecting torch (from -r requirements.txt (line 2))\n","  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from torch->-r requirements.txt (line 2))\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.1.0 (from torch->-r requirements.txt (line 2))\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2))\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->-r requirements.txt (line 4)) (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost->-r requirements.txt (line 6)) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->-r requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->-r requirements.txt (line 8)) (0.18.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt->-r requirements.txt (line 8)) (4.66.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->-r requirements.txt (line 8)) (2.2.1)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->-r requirements.txt (line 8)) (0.10.9.7)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.4.0)\n","Collecting rdkit-pypi (from drfp->-r requirements.txt (line 13))\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.10/dist-packages (from drfp->-r requirements.txt (line 13)) (8.1.7)\n","Requirement already satisfied: attrs>=17.2.0 in /usr/local/lib/python3.10/dist-packages (from zeep->-r requirements.txt (line 14)) (23.2.0)\n","Collecting isodate>=0.5.4 (from zeep->-r requirements.txt (line 14))\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from zeep->-r requirements.txt (line 14)) (4.9.4)\n","Requirement already satisfied: platformdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from zeep->-r requirements.txt (line 14)) (4.2.0)\n","Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from zeep->-r requirements.txt (line 14)) (2.31.0)\n","Collecting requests-toolbelt>=0.7.1 (from zeep->-r requirements.txt (line 14))\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-file>=1.5.1 (from zeep->-r requirements.txt (line 14))\n","  Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: appdirs~=1.4 in /usr/local/lib/python3.10/dist-packages (from cobra->-r requirements.txt (line 15)) (1.4.4)\n","Collecting depinfo~=2.2 (from cobra->-r requirements.txt (line 15))\n","  Downloading depinfo-2.2.0-py3-none-any.whl (24 kB)\n","Collecting diskcache~=5.0 (from cobra->-r requirements.txt (line 15))\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx~=0.24 (from cobra->-r requirements.txt (line 15))\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from cobra->-r requirements.txt (line 15)) (6.4.0)\n","Collecting optlang~=1.8 (from cobra->-r requirements.txt (line 15))\n","  Downloading optlang-1.8.1-py2.py3-none-any.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=1.6 in /usr/local/lib/python3.10/dist-packages (from cobra->-r requirements.txt (line 15)) (2.6.4)\n","Collecting python-libsbml~=5.19 (from cobra->-r requirements.txt (line 15))\n","  Downloading python_libsbml-5.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rich>=8.0 in /usr/local/lib/python3.10/dist-packages (from cobra->-r requirements.txt (line 15)) (13.7.1)\n","Collecting ruamel.yaml~=0.16 (from cobra->-r requirements.txt (line 15))\n","  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting swiglpk (from cobra->-r requirements.txt (line 15))\n","  Downloading swiglpk-5.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bioservices->-r requirements.txt (line 18)) (4.12.3)\n","Collecting colorlog (from bioservices->-r requirements.txt (line 18))\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Collecting easydev>=0.12.0 (from bioservices->-r requirements.txt (line 18))\n","  Downloading easydev-0.13.1-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grequests (from bioservices->-r requirements.txt (line 18))\n","  Downloading grequests-0.7.0-py2.py3-none-any.whl (5.7 kB)\n","Collecting requests_cache (from bioservices->-r requirements.txt (line 18))\n","  Downloading requests_cache-1.2.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting suds-community>=0.7 (from bioservices->-r requirements.txt (line 18))\n","  Downloading suds_community-1.1.2-py3-none-any.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.9/144.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from bioservices->-r requirements.txt (line 18)) (1.14.1)\n","Collecting xmltodict (from bioservices->-r requirements.txt (line 18))\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n","Collecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading fastapi-0.109.1-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.36.0,>=0.35.0 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.33.0,>=0.29.0 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.107.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 19)) (3.7.1)\n","Collecting starlette<0.29.0,>=0.28.0 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.28.0-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.106.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->-r requirements.txt (line 19))\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n","Collecting fastapi (from -r requirements.txt (line 19))\n","  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11>=0.8 (from uvicorn->-r requirements.txt (line 22))\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 19)) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 19)) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 19)) (1.2.0)\n","Collecting colorama<0.5.0,>=0.4.6 (from easydev>=0.12.0->bioservices->-r requirements.txt (line 18))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting line-profiler<5.0.0,>=4.1.2 (from easydev>=0.12.0->bioservices->-r requirements.txt (line 18))\n","  Downloading line_profiler-4.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (714 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m714.8/714.8 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from easydev>=0.12.0->bioservices->-r requirements.txt (line 18)) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.24->cobra->-r requirements.txt (line 15)) (2024.2.2)\n","Collecting httpcore==1.* (from httpx~=0.24->cobra->-r requirements.txt (line 15))\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.6->cobra->-r requirements.txt (line 15)) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.6->cobra->-r requirements.txt (line 15)) (2.16.3)\n","INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n","Collecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.18.1 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pydantic-2.6.2-py3-none-any.whl (394 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.16.2 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.16.1 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.14.6 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.14.5 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n","Collecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.14.3 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.14.1 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.10.1 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.4.1-py3-none-any.whl (395 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/395.3 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pydantic-2.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/395.4 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.10.0 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","Collecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.3.0-py3-none-any.whl (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.6.3 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.2.1-py3-none-any.whl (373 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.4/373.4 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.6.1 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.2.0-py3-none-any.whl (373 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.2/373.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.6.0 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.1.1-py3-none-any.whl (370 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.4.0 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.0.3-py3-none-any.whl (364 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.0/364.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.3.0 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-2.0.2-py3-none-any.whl (359 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.1/359.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic-core==2.1.2 (from pydantic>=1.6->cobra->-r requirements.txt (line 15))\n","  Downloading pydantic_core-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic>=1.6 (from cobra->-r requirements.txt (line 15))\n","  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->zeep->-r requirements.txt (line 14)) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->zeep->-r requirements.txt (line 14)) (2.0.7)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=8.0->cobra->-r requirements.txt (line 15)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=8.0->cobra->-r requirements.txt (line 15)) (2.16.1)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml~=0.16->cobra->-r requirements.txt (line 15))\n","  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bioservices->-r requirements.txt (line 18)) (2.5)\n","Collecting gevent (from grequests->bioservices->-r requirements.txt (line 18))\n","  Downloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.5)\n","Collecting cattrs>=22.2 (from requests_cache->bioservices->-r requirements.txt (line 18))\n","  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting url-normalize>=1.4 (from requests_cache->bioservices->-r requirements.txt (line 18))\n","  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=8.0->cobra->-r requirements.txt (line 15)) (0.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev>=0.12.0->bioservices->-r requirements.txt (line 18)) (0.7.0)\n","Collecting zope.event (from gevent->grequests->bioservices->-r requirements.txt (line 18))\n","  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n","Collecting zope.interface (from gevent->grequests->bioservices->-r requirements.txt (line 18))\n","  Downloading zope.interface-6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent->grequests->bioservices->-r requirements.txt (line 18)) (3.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.event->gevent->grequests->bioservices->-r requirements.txt (line 18)) (67.7.2)\n","Building wheels for collected packages: pickle5, pubchempy, bioservices\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255319 sha256=faecc724148c36fb1df53159a8da30f76e991199ad1808d2b1b85894e44eaa73\n","  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n","  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pubchempy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13820 sha256=f6c9a769f4b15aaa7d873282268052a3f4d8ae2c2eb592deae10c7d2ed1c379d\n","  Stored in directory: /root/.cache/pip/wheels/90/7c/45/18a0671e3c3316966ef7ed9ad2b3f3300a7e41d3421a44e799\n","  Building wheel for bioservices (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bioservices: filename=bioservices-1.11.2-py3-none-any.whl size=223232 sha256=3cc529b7058c23574258e4dc2e3aba2e2ee7c8f9c1893d8de528ca4174d181a9\n","  Stored in directory: /root/.cache/pip/wheels/bf/ac/b3/dc05e53581bbb58641e9ac52428b89d7fc0d9ddc44f9b16456\n","Successfully built pickle5 pubchempy bioservices\n","Installing collected packages: swiglpk, python-libsbml, pubchempy, pickle5, kaleido, fair-esm, zope.interface, zope.event, xmltodict, url-normalize, typing-extensions, triton, suds-community, suds, ruamel.yaml.clib, rdkit-pypi, rdkit, python-multipart, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, line-profiler, isodate, h11, diskcache, depinfo, colorlog, colorama, biopython, uvicorn, starlette, ruamel.yaml, requests-toolbelt, requests-file, pydantic, pandas, optlang, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, gevent, easydev, drfp, cattrs, zeep, requests_cache, nvidia-cusolver-cu12, httpx, grequests, fastapi, torch, cobra, bioservices\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.11.0\n","    Uninstalling typing_extensions-4.11.0:\n","      Successfully uninstalled typing_extensions-4.11.0\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.2.0\n","    Uninstalling triton-2.2.0:\n","      Successfully uninstalled triton-2.2.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.6.4\n","    Uninstalling pydantic-2.6.4:\n","      Successfully uninstalled pydantic-2.6.4\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sqlalchemy 2.0.29 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n","pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n","torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed biopython-1.83 bioservices-1.11.2 cattrs-23.2.3 cobra-0.29.0 colorama-0.4.6 colorlog-6.8.2 depinfo-2.2.0 diskcache-5.6.3 drfp-0.3.6 easydev-0.13.1 fair-esm-2.0.0 fastapi-0.103.2 gevent-24.2.1 grequests-0.7.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 isodate-0.6.1 kaleido-0.2.1 line-profiler-4.1.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optlang-1.8.1 pandas-1.5.3 pickle5-0.0.11 pubchempy-1.0.4 pydantic-1.10.15 python-libsbml-5.20.2 python-multipart-0.0.9 rdkit-2023.9.5 rdkit-pypi-2022.9.5 requests-file-2.0.0 requests-toolbelt-1.0.0 requests_cache-1.2.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 starlette-0.27.0 suds-1.1.2 suds-community-1.1.2 swiglpk-5.0.10 torch-2.1.2 triton-2.1.0 typing-extensions-4.5.0 url-normalize-1.4.3 uvicorn-0.29.0 xmltodict-0.13.0 zeep-4.2.1 zope.event-5.0 zope.interface-6.3\n"]}],"source":["%cd /content/drive/MyDrive/enz-eff-project\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RUbtJxmu3Fyo","outputId":"21ea6a3b-027e-4de1-ca89-dff5036e87d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-determinism\n","  Downloading tensorflow_determinism-0.4.0-py3-none-any.whl (3.9 kB)\n","Installing collected packages: tensorflow-determinism\n","Successfully installed tensorflow-determinism-0.4.0\n"]}],"source":["!pip install tensorflow-determinism"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kW5ulYTp3jI","executionInfo":{"status":"ok","timestamp":1712991977293,"user_tz":-300,"elapsed":44,"user":{"displayName":"M Faizan","userId":"01979528019072830709"}},"outputId":"6e48ebee-6b38-4102-a489-42347a1cbae0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1iS6gSWfUE3cZnmrNWbbV9_W_zQH3vaiu/enz-eff-project/improved_code/model_training\n"]}],"source":["%cd improved_code/model_training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgTyQRleNmc-"},"outputs":[],"source":["%ls"]},{"cell_type":"markdown","metadata":{"id":"d2JjjXGzr8ky"},"source":["# CNN\n","Hyperparameter tuning +  Model training + saving best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28460,"status":"ok","timestamp":1712992006538,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"FFOh28hMyzRc","outputId":"c3132ec4-40f2-40c8-ec8b-b623b5b13392"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3391, 30), (874, 30))"]},"metadata":{},"execution_count":5}],"source":["import random\n","random.seed(42)  # define seed\n","\n","import numpy as np\n","np.random.seed(42)  # define seed\n","\n","import tensorflow as tf\n","tf.random.set_seed(42)  # define seed\n","\n","# Reduce randomness due the GPU manipulation\n","tf.config.experimental.enable_tensor_float_32_execution(False)\n","tf.config.optimizer.set_jit(False)\n","tf.config.experimental.list_physical_devices('GPU')\n","\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set to the desired GPU device\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","os.environ['OMP_NUM_THREADS'] = '1'\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import keras\n","keras.utils.set_random_seed(42)\n","import pandas as pd\n","import numpy as np\n","from os.path import join\n","from tensorflow import keras\n","from sklearn.metrics import mean_squared_error, r2_score\n","from tensorflow.keras.models import save_model\n","from tensorflow.keras.initializers import glorot_normal\n","from tensorflow import keras\n","from scipy.optimize import minimize\n","from utils import (get_processed_data,\n","                   create_model,\n","                   save_best_params,\n","                   is_not_require_params,\n","                   train_model,\n","                   calculate_weighted_mean,\n","                   evaluate_model,\n","                   get_model_preds,\n","                   delete_file,\n","                   empty_directory,\n","                   )\n","\n","# load train and test dataset\n","data_train = pd.read_pickle(\n","    join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"train_df_kcat_new.pkl\")\n",")\n","data_test = pd.read_pickle(\n","    join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"test_df_kcat_new.pkl\")\n",")\n","\n","train_indices = list(\n","    np.load(\n","        join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"CV_train_indices.npy\"),\n","        allow_pickle = True\n","        ))\n","test_indices = list(\n","    np.load(\n","        join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"CV_test_indices.npy\"),\n","        allow_pickle = True)\n","        )\n","\n","data_train.shape, data_test.shape"]},{"cell_type":"markdown","metadata":{"id":"kUFhyI2Dr8ky"},"source":["## ESM1b + DRFP"]},{"cell_type":"markdown","metadata":{"id":"V3qa1i7Er8kz"},"source":["### Hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YK8aQRGh0StO"},"outputs":[],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","BEST_MODEL = \"../../models/hyperparam_tune_models/cnn_best_esm1b_drfp.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/cnn_hyperparam_esm1b_drfp.txt\"\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","\n","\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"DRFP\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"DRFP\"],\n","                                          data_test[\"ESM1b_norm\"]],\n","                                          data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"3sejL-rxr8k0"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256396,"status":"ok","timestamp":1712992421429,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"qG1MERF2r8k0","outputId":"9ab88c4a-a10f-4dcf-ae35-da21c6fc6ecf"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 4ms/step\n","Model-1 results {'mse': 0.49, 'R2 score': 0.48, 'pearson coefficient': 0.7}\n","28/28 [==============================] - 0s 3ms/step\n","Model-2 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-3 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-4 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","ensemble output: {'mse': 0.49, 'R2 score': 0.49, 'pearson coefficient': 0.7}\n"]}],"source":["# Trained Model path\n","MODEL_DIR = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","\n","# Trained hyperparameter\n","'''\n","HYPER_PARAMS = {\n","    \"filters_1\": 8,\n","    \"filters_2\": 22,\n","    \"filters_3\": 28,\n","    \"kernel_size_1\": 13,\n","    \"kernel_size_2\": 15,\n","    \"kernel_size_3\": 11,\n","    \"dense_units_1\": 512,\n","    \"dense_units_2\": 32,\n","    \"dropout_rate\": 0.2,\n","    \"optimizer\": \"rmsprop\",\n","    \"batch_size\": 16,\n","}\n","\n","HYPER_PARAMS = {\n","    'filters_1': 8,\n","    'filters_2': 24,\n","    'filters_3': 28,\n","    'kernel_size_1': 3,\n","    'kernel_size_2': 13,\n","    'kernel_size_3': 7,\n","    'dense_units_1': 128,\n","    'dense_units_2': 8,\n","    'dropout_rate': 0.1,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 32\n","}\n","'''\n","\n","HYPER_PARAMS = {\n","    'filters_1': 4,\n","    'filters_2': 8,\n","    'filters_3': 24,\n","    'kernel_size_1': 11,\n","    'kernel_size_2': 7,\n","    'kernel_size_3': 11,\n","    'dense_units_1': 512,\n","    'dense_units_2': 256,\n","    'dropout_rate': 0.2,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 8\n","    }\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"DRFP\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"DRFP\"],\n","                                        data_test[\"ESM1b_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"ensemble output: {evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_drfp_weighted_pred = weighted_avg_pred\n"]},{"cell_type":"markdown","metadata":{"id":"1HcDP88QS0dQ"},"source":["Model-1 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 2ms/step\n","Model-2 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 2ms/step\n","Model-3 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 2ms/step\n","Model-4 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","ensemble output: {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}"]},{"cell_type":"markdown","metadata":{"id":"SI5s4k_Or8k0"},"source":["## ESM1b + Difference"]},{"cell_type":"markdown","metadata":{"id":"SZ3_HWLl6Aht"},"source":["### Hyperparameter optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCqs_kx8z8TH"},"outputs":[],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","BEST_MODEL = \"../../models/hyperparam_tune_models/esm1b_diff.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/esm1b_diff.txt\"\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","\n","\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"difference_fp\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"difference_fp\"],\n","                                        data_test[\"ESM1b_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"3mTbpAhKr8k1"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99908,"status":"ok","timestamp":1712993060527,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"CPO_9atvr8k1","outputId":"d5543451-c116-43e4-fc33-2092e931e053"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 3ms/step\n","Model-1 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-2 results {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-3 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-4 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.5, 'R2 score': 0.47, 'pearson coefficient': 0.69}\n","ensemble output: {'mse': 0.5, 'R2 score': 0.48, 'pearson coefficient': 0.69}\n"]}],"source":["MODEL_DIR = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","\n","# Trained hyperparameter\n","'''\n","\n","HYPER_PARAMS = {\n","    \"filters_1\": 6,\n","    \"filters_2\": 6,\n","    \"filters_3\": 16,\n","    \"kernel_size_1\": 13,\n","    \"kernel_size_2\": 5,\n","    \"kernel_size_3\": 13,\n","    \"dense_units_1\": 256,\n","    \"dense_units_2\": 8,\n","    \"dropout_rate\": 0.5,\n","    \"optimizer\": \"nadam\",\n","    \"batch_size\": 24,\n","}\n","\n","HYPER_PARAMS = {\n","    'filters_1': 2,\n","    'filters_2': 8,\n","    'filters_3': 12,\n","    'kernel_size_1': 17,\n","    'kernel_size_2': 9,\n","    'kernel_size_3': 13,\n","    'dense_units_1': 512,\n","    'dense_units_2': 256,\n","    'dropout_rate': 0.1,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 8\n","}\n","\n","HYPER_PARAMS = {\n","    'filters_1': 6,\n","    'filters_2': 12,\n","    'filters_3': 26,\n","    'kernel_size_1': 15,\n","    'kernel_size_2': 5,\n","    'kernel_size_3': 9,\n","    'dense_units_1': 256,\n","    'dense_units_2': 32,\n","    'dropout_rate': 0.1,\n","    'optimizer': 'nadam',\n","    'batch_size': 8\n","    }\n","'''\n","\n","HYPER_PARAMS = {\n","    'filters_1': 10,\n","    'filters_2': 10,\n","    'filters_3': 10,\n","    'kernel_size_1': 5,\n","    'kernel_size_2': 11,\n","    'kernel_size_3': 11,\n","    'dense_units_1': 512,\n","    'dense_units_2': 16,\n","    'dropout_rate': 0.5,\n","    'optimizer': 'nadam',\n","    'batch_size': 64\n","    }\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"difference_fp\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"difference_fp\"],\n","                                        data_test[\"ESM1b_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"ensemble output: {evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_diff_weighted_pred = weighted_avg_pred"]},{"cell_type":"markdown","metadata":{"id":"gypnprhGr8k1"},"source":["## ESM1b_ts + DRFP"]},{"cell_type":"markdown","metadata":{"id":"eII0mb3lr8k2"},"source":["### Hyperparameter optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jANpv1kU0o_D"},"outputs":[],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","BEST_MODEL = \"../../models/hyperparam_tune_models/esm1b_ts_drfp.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/esm1b_ts_drfp.txt\"\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"DRFP\"],\n","                                          data_train[\"ESM1b_ts_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"DRFP\"],\n","                                          data_test[\"ESM1b_ts_norm\"]],\n","                                          data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"Jdi0gDZvr8k2"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61388,"status":"ok","timestamp":1712993121880,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"6-Fx7Zzdr8k2","outputId":"374ec5f0-7d04-46ea-ac74-466577b8b715"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 3ms/step\n","Model-1 results {'mse': 0.51, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","28/28 [==============================] - 0s 4ms/step\n","Model-2 results {'mse': 0.51, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","28/28 [==============================] - 0s 3ms/step\n","Model-3 results {'mse': 0.51, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","28/28 [==============================] - 0s 4ms/step\n","Model-4 results {'mse': 0.51, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.51, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","final output{'mse': 0.51, 'R2 score': 0.47, 'pearson coefficient': 0.68}\n"]}],"source":["BEST_MODEL = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","\n","\n","# Trained hyperparameter\n","'''\n","HYPER_PARAMS = {\n","    \"filters_1\": 4,\n","    \"filters_2\": 14,\n","    \"filters_3\": 16,\n","    \"kernel_size_1\": 13,\n","    \"kernel_size_2\": 9,\n","    \"kernel_size_3\": 11,\n","    \"dense_units_1\": 512,\n","    \"dense_units_2\": 128,\n","    \"dropout_rate\": 0.3,\n","    \"optimizer\": \"rmsprop\",\n","    \"batch_size\": 8,\n","}\n","'''\n","HYPER_PARAMS = {\n","    'filters_1': 12,\n","    'filters_2': 22,\n","    'filters_3': 28,\n","    'kernel_size_1': 5,\n","    'kernel_size_2': 5,\n","    'kernel_size_3': 9,\n","    'dense_units_1': 64,\n","    'dense_units_2': 8,\n","    'dropout_rate': 0.2,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 128\n","    }\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"DRFP\"],\n","                                          data_train[\"ESM1b_ts_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"DRFP\"],\n","                                        data_test[\"ESM1b_ts_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"final output{evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_ts_drfp_weighted_pred = weighted_avg_pred\n"]},{"cell_type":"markdown","metadata":{"id":"zs5bYsXHr8k3"},"source":["## ESM1bts + Difference FP"]},{"cell_type":"markdown","metadata":{"id":"FVIsoIBOr8k3"},"source":["### Hyperparameter optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wShCpINi0vyN","outputId":"5263c97c-dab8-4bcb-d72b-43a8cf18460b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration-0...\n","Iteration-1...\n","28/28 [==============================] - 0s 3ms/step\n","New best R2 score: 0.43\n","New Best hyperparameters: {'filters_1': 8, 'filters_2': 20, 'filters_3': 28, 'kernel_size_1': 11, 'kernel_size_2': 13, 'kernel_size_3': 13, 'dense_units_1': 64, 'dense_units_2': 8, 'dropout_rate': 0.1, 'optimizer': 'rmsprop', 'batch_size': 128}\n","Iteration-2...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-3...\n","Iteration-4...\n","Iteration-5...\n","28/28 [==============================] - 0s 3ms/step\n","New best R2 score: 0.44\n","New Best hyperparameters: {'filters_1': 10, 'filters_2': 20, 'filters_3': 20, 'kernel_size_1': 15, 'kernel_size_2': 9, 'kernel_size_3': 9, 'dense_units_1': 256, 'dense_units_2': 64, 'dropout_rate': 0.4, 'optimizer': 'rmsprop', 'batch_size': 128}\n","Iteration-6...\n","28/28 [==============================] - 0s 4ms/step\n","New best R2 score: 0.45\n","New Best hyperparameters: {'filters_1': 10, 'filters_2': 10, 'filters_3': 10, 'kernel_size_1': 5, 'kernel_size_2': 11, 'kernel_size_3': 11, 'dense_units_1': 512, 'dense_units_2': 16, 'dropout_rate': 0.5, 'optimizer': 'nadam', 'batch_size': 64}\n","Iteration-7...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-8...\n","28/28 [==============================] - 0s 4ms/step\n","New best R2 score: 0.46\n","New Best hyperparameters: {'filters_1': 4, 'filters_2': 6, 'filters_3': 8, 'kernel_size_1': 5, 'kernel_size_2': 5, 'kernel_size_3': 13, 'dense_units_1': 256, 'dense_units_2': 8, 'dropout_rate': 0.4, 'optimizer': 'nadam', 'batch_size': 8}\n","Iteration-9...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-10...\n","Iteration-11...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-12...\n","Iteration-13...\n","Iteration-14...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-15...\n","28/28 [==============================] - 0s 3ms/step\n","New best R2 score: 0.47\n","New Best hyperparameters: {'filters_1': 2, 'filters_2': 8, 'filters_3': 16, 'kernel_size_1': 5, 'kernel_size_2': 7, 'kernel_size_3': 9, 'dense_units_1': 512, 'dense_units_2': 128, 'dropout_rate': 0.5, 'optimizer': 'adam', 'batch_size': 8}\n","Iteration-16...\n","Iteration-17...\n","Iteration-18...\n","Iteration-19...\n","28/28 [==============================] - 0s 2ms/step\n","Iteration-20...\n","Iteration-21...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-22...\n","28/28 [==============================] - 0s 2ms/step\n","Iteration-23...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-24...\n","Iteration-25...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-26...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-27...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-28...\n","28/28 [==============================] - 0s 2ms/step\n","Iteration-29...\n","Iteration-30...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-31...\n","Iteration-32...\n","Iteration-33...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-34...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-35...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-36...\n","28/28 [==============================] - 0s 3ms/step\n","New best R2 score: 0.48\n","New Best hyperparameters: {'filters_1': 12, 'filters_2': 12, 'filters_3': 14, 'kernel_size_1': 13, 'kernel_size_2': 15, 'kernel_size_3': 9, 'dense_units_1': 512, 'dense_units_2': 8, 'dropout_rate': 0.5, 'optimizer': 'adam', 'batch_size': 32}\n","Iteration-37...\n","Iteration-38...\n","Iteration-39...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-40...\n","Iteration-41...\n","Iteration-42...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-43...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-44...\n","Iteration-45...\n","Iteration-46...\n","Iteration-47...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-48...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-49...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-50...\n","Iteration-51...\n","Iteration-52...\n","Iteration-53...\n","Iteration-54...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-55...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-56...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-57...\n","Iteration-58...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-59...\n","Iteration-60...\n","Iteration-61...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-62...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-63...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-64...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-65...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-66...\n","Iteration-67...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-68...\n","Iteration-69...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-70...\n","Iteration-71...\n","Iteration-72...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-73...\n","Iteration-74...\n","Iteration-75...\n"]}],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","PROCESSED_PARAMS = \"../../models/hyperparam_tune_models/processed_params_esm1b_ts_diff.txt\"\n","BEST_MODEL = \"../../models/hyperparam_tune_models/esm1b_ts_diff.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/esm1b_ts_diff.txt\"\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","\n","    train_X, train_Y = get_processed_data([data_train[\"difference_fp\"],\n","                                          data_train[\"ESM1b_ts_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"difference_fp\"],\n","                                        data_test[\"ESM1b_ts_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"V0QaLDoDr8k4"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180701,"status":"ok","timestamp":1712993403552,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"gIQes-Ozr8k4","outputId":"0ca623b1-f021-4825-bc3c-3292bf8f50af"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 3ms/step\n","Model-1 results {'mse': 0.56, 'R2 score': 0.41, 'pearson coefficient': 0.64}\n","28/28 [==============================] - 0s 3ms/step\n","Model-2 results {'mse': 0.52, 'R2 score': 0.46, 'pearson coefficient': 0.68}\n","28/28 [==============================] - 0s 3ms/step\n","Model-3 results {'mse': 0.52, 'R2 score': 0.45, 'pearson coefficient': 0.67}\n","28/28 [==============================] - 0s 4ms/step\n","Model-4 results {'mse': 0.52, 'R2 score': 0.45, 'pearson coefficient': 0.67}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.52, 'R2 score': 0.45, 'pearson coefficient': 0.67}\n","final output{'mse': 0.51, 'R2 score': 0.47, 'pearson coefficient': 0.68}\n"]}],"source":["MODEL_DIR = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","\n","# Trained hyperparameter\n","'''\n","HYPER_PARAMS = {\n","    \"filters_1\": 14,\n","    \"filters_2\": 14,\n","    \"filters_3\": 24,\n","    \"kernel_size_1\": 3,\n","    \"kernel_size_2\": 9,\n","    \"kernel_size_3\": 9,\n","    \"dense_units_1\": 512,\n","    \"dense_units_2\": 128,\n","    # \"dense_units_3\": 16,\n","    \"dropout_rate\": 0.1,\n","    \"optimizer\": \"adam\",\n","    \"batch_size\": 8,\n","}\n","'''\n","\n","HYPER_PARAMS = {\n","    'filters_1': 12,\n","    'filters_2': 12,\n","    'filters_3': 14,\n","    'kernel_size_1': 13,\n","    'kernel_size_2': 15,\n","    'kernel_size_3': 9,\n","    'dense_units_1': 512,\n","    'dense_units_2': 8,\n","    'dropout_rate': 0.5,\n","    'optimizer': 'adam',\n","    'batch_size': 32\n","    }\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","\n","    train_X, train_Y = get_processed_data([data_train[\"difference_fp\"],\n","                                              data_train[\"ESM1b_ts_norm\"]],\n","                                              data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"difference_fp\"],\n","                                        data_test[\"ESM1b_ts_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"final output{evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_ts_diff_weighted_pred = weighted_avg_pred"]},{"cell_type":"markdown","metadata":{"id":"kikgY_2gr8k5"},"source":["## ESM1b + Structural FP"]},{"cell_type":"markdown","metadata":{"id":"9sLMThO6r8k5"},"source":["### Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfFpF4U_02cC"},"outputs":[],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","BEST_MODEL = \"../../models/hyperparam_tune_models/esm1b_struct.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/esm1b_struct.txt\"\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"structural_fp\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data(data_test[\"structural_fp\"],\n","                                        data_test[\"ESM1b_norm\"],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"-bXjz9jfr8k6"},"source":["###Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100089,"status":"ok","timestamp":1712993504194,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"0W6hbtslNZM0","outputId":"888b1632-8c50-48ef-ba28-0e4b30079dcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 4ms/step\n","Model-1 results {'mse': 0.6, 'R2 score': 0.37, 'pearson coefficient': 0.61}\n","28/28 [==============================] - 0s 3ms/step\n","Model-2 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","28/28 [==============================] - 0s 3ms/step\n","Model-3 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","28/28 [==============================] - 0s 5ms/step\n","Model-4 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","28/28 [==============================] - 0s 4ms/step\n","Model-5 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","final output{'mse': 0.56, 'R2 score': 0.41, 'pearson coefficient': 0.64}\n"]}],"source":["MODEL_DIR = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","# Trained hyperparameter\n","'''\n","HYPER_PARAMS = {\n","    \"filters_1\": 6,\n","    \"filters_2\": 6,\n","    \"filters_3\": 22,\n","    \"kernel_size_1\": 9,\n","    \"kernel_size_2\": 15,\n","    \"kernel_size_3\": 13,\n","    \"dense_units_1\": 256,\n","    \"dense_units_2\": 128,\n","    \"dropout_rate\": 0.2,\n","    \"optimizer\": \"adam\",\n","    \"batch_size\": 128,\n","}\n","\n","HYPER_PARAMS = {\n","    'filters_1': 6,\n","    'filters_2': 18,\n","    'filters_3': 22,\n","    'kernel_size_1': 5,\n","    'kernel_size_2': 9,\n","    'kernel_size_3': 7,\n","    'dense_units_1': 64,\n","    'dense_units_2': 8,\n","    'dropout_rate': 0.3,\n","    'optimizer': 'nadam',\n","    'batch_size': 24\n","    }\n","'''\n","HYPER_PARAMS = {\n","    'filters_1': 8,\n","    'filters_2': 12,\n","    'filters_3': 20,\n","    'kernel_size_1': 9,\n","    'kernel_size_2': 15,\n","    'kernel_size_3': 7,\n","    'dense_units_1': 512,\n","    'dense_units_2': 64,\n","    'dropout_rate': 0.3,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 32\n","    }\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"structural_fp\"],\n","                                          data_train[\"ESM1b_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"structural_fp\"],\n","                                          data_test[\"ESM1b_norm\"]],\n","                                          data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"final output{evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_struct_weighted_pred = weighted_avg_pred\n"]},{"cell_type":"markdown","metadata":{"id":"-0HSoKA2r8k6"},"source":["## ESM1b_ts + Structural FP"]},{"cell_type":"markdown","metadata":{"id":"84UGXLF59QAK"},"source":["### Hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77hGfz4O090a","outputId":"ec99c41e-75b9-40ef-fede-81ffaa5b83b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration-0...\n","Iteration-1...\n","Iteration-2...\n","Iteration-3...\n","28/28 [==============================] - 0s 5ms/step\n","New best R2 score: 0.41\n","New Best hyperparameters: {'filters_1': 6, 'filters_2': 22, 'filters_3': 30, 'kernel_size_1': 9, 'kernel_size_2': 15, 'kernel_size_3': 9, 'dense_units_1': 256, 'dense_units_2': 256, 'dropout_rate': 0.3, 'optimizer': 'rmsprop', 'batch_size': 32}\n","Iteration-4...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-5...\n","Iteration-6...\n","Iteration-7...\n","Iteration-8...\n","Iteration-9...\n","Iteration-10...\n","Iteration-11...\n","28/28 [==============================] - 0s 4ms/step\n","New best R2 score: 0.43\n","New Best hyperparameters: {'filters_1': 6, 'filters_2': 8, 'filters_3': 8, 'kernel_size_1': 7, 'kernel_size_2': 13, 'kernel_size_3': 9, 'dense_units_1': 256, 'dense_units_2': 16, 'dropout_rate': 0.1, 'optimizer': 'rmsprop', 'batch_size': 8}\n","Iteration-12...\n","Iteration-13...\n","Iteration-14...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-15...\n","28/28 [==============================] - 0s 5ms/step\n","New best R2 score: 0.44\n","New Best hyperparameters: {'filters_1': 8, 'filters_2': 10, 'filters_3': 34, 'kernel_size_1': 11, 'kernel_size_2': 13, 'kernel_size_3': 11, 'dense_units_1': 256, 'dense_units_2': 128, 'dropout_rate': 0.4, 'optimizer': 'nadam', 'batch_size': 24}\n","Iteration-16...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-17...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-18...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-19...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-20...\n","Iteration-21...\n","Iteration-22...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-23...\n","Iteration-24...\n","Iteration-25...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-26...\n","Iteration-27...\n","Iteration-28...\n","28/28 [==============================] - 0s 3ms/step\n","New best R2 score: 0.45\n","New Best hyperparameters: {'filters_1': 2, 'filters_2': 8, 'filters_3': 12, 'kernel_size_1': 17, 'kernel_size_2': 9, 'kernel_size_3': 13, 'dense_units_1': 512, 'dense_units_2': 256, 'dropout_rate': 0.1, 'optimizer': 'rmsprop', 'batch_size': 8}\n","Iteration-29...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-30...\n","Iteration-31...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-32...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-33...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-34...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-35...\n","Iteration-36...\n","Iteration-37...\n","Iteration-38...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-39...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-40...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-41...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-42...\n","Iteration-43...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-44...\n","Iteration-45...\n","Iteration-46...\n","Iteration-47...\n","Iteration-48...\n","Iteration-49...\n","Iteration-50...\n","Iteration-51...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-52...\n","Iteration-53...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-54...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-55...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-56...\n","Iteration-57...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-58...\n","Iteration-59...\n","Iteration-60...\n","Iteration-61...\n","Iteration-62...\n","Iteration-63...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-64...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-65...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-66...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-67...\n","Iteration-68...\n","Iteration-69...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-70...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-71...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-72...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-73...\n","Iteration-74...\n","Iteration-75...\n","Iteration-76...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-77...\n","Iteration-78...\n","Iteration-79...\n","Iteration-80...\n","Iteration-81...\n","Iteration-82...\n","Iteration-83...\n","Iteration-84...\n","Iteration-85...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-86...\n","Iteration-87...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-88...\n","Iteration-89...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-90...\n","Iteration-91...\n","Iteration-92...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-93...\n","Iteration-94...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-95...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-96...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-97...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-98...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-99...\n","Iteration-100...\n","Iteration-101...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-102...\n","28/28 [==============================] - 0s 4ms/step\n","New best R2 score: 0.47\n","New Best hyperparameters: {'filters_1': 4, 'filters_2': 14, 'filters_3': 16, 'kernel_size_1': 13, 'kernel_size_2': 9, 'kernel_size_3': 11, 'dense_units_1': 512, 'dense_units_2': 128, 'dropout_rate': 0.3, 'optimizer': 'rmsprop', 'batch_size': 8}\n","Iteration-103...\n","Iteration-104...\n","Iteration-105...\n","Iteration-106...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-107...\n","Iteration-108...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-109...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-110...\n","Iteration-111...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-112...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-113...\n","Iteration-114...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-115...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-116...\n","Iteration-117...\n","Iteration-118...\n","Iteration-119...\n","Iteration-120...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-121...\n","Iteration-122...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-123...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-124...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-125...\n","Iteration-126...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-127...\n","Iteration-128...\n","Iteration-129...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-130...\n","Iteration-131...\n","Iteration-132...\n","Iteration-133...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-134...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-135...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-136...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-137...\n","Iteration-138...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-139...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-140...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-141...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-142...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-143...\n","Iteration-144...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-145...\n","Iteration-146...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-147...\n","Iteration-148...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-149...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-150...\n","Iteration-151...\n","Iteration-152...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-153...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-154...\n","Iteration-155...\n","Iteration-156...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-157...\n","Iteration-158...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-159...\n","Iteration-160...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-161...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-162...\n","Iteration-163...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-164...\n","Iteration-165...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-166...\n","Iteration-167...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-168...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-169...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-170...\n","Iteration-171...\n","Iteration-172...\n","Iteration-173...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-174...\n","Iteration-175...\n","28/28 [==============================] - 0s 6ms/step\n","Iteration-176...\n","Iteration-177...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-178...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-179...\n","Iteration-180...\n","Iteration-181...\n","Iteration-182...\n","Iteration-183...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-184...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-185...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-186...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-187...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-188...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-189...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-190...\n","28/28 [==============================] - 0s 3ms/step\n","Iteration-191...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-192...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-193...\n","Iteration-194...\n","Iteration-195...\n","28/28 [==============================] - 0s 4ms/step\n","Iteration-196...\n","Iteration-197...\n","28/28 [==============================] - 0s 5ms/step\n","Iteration-198...\n","Iteration-199...\n","28/28 [==============================] - 0s 3ms/step\n"]}],"source":["BEST_R2 = 0\n","BEST_HYPER_PARAMS = None\n","PROCESSED_PARAMS = \"../../models/hyperparam_tune_models/processed_params_esm1b_ts_struct.txt\"\n","BEST_MODEL = \"../../models/hyperparam_tune_models/esm1b_ts_struct.h5\"\n","BEST_HYPER_PARAMS_FILE = \"../../hyperparameters/esm1b_ts_struct.txt\"\n","\n","# Note: Due to limited GPU access time on Colab, if hyperparameter tuning stops at some point,\n","# we can resume the iteration from the point where it left off.\n","# Set the starting point for iteration\n","START = 0\n","# Define the total number of iterations (assuming you want to perform 1000 iterations in total)\n","TOTAL_ITERATION = 500\n","\n","\n","# Define the hyperparameter search space\n","PARAM_SPACE = {\n","    \"filters_1\": list(range(2, 15, 2)),\n","    \"filters_2\": list(range(4, 25, 2)),\n","    \"filters_3\": list(range(8, 35, 2)),\n","    \"kernel_size_1\": list(range(3, 19, 2)),\n","    \"kernel_size_2\": list(range(5, 17, 2)),\n","    \"kernel_size_3\": list(range(7, 15, 2)),\n","    \"dense_units_1\": [64, 128, 256, 512],\n","    \"dense_units_2\": [8, 16, 32, 64, 128, 256],\n","    \"dropout_rate\": [0.10, 0.2, 0.3, 0.4, 0.5],\n","    \"optimizer\": [\"nadam\", \"adam\", \"rmsprop\"],\n","    \"batch_size\": [8, 16, 24, 32, 64, 128],\n","}\n","\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"structural_fp\"],\n","                                          data_train[\"ESM1b_ts_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"structural_fp\"],\n","                                        data_test[\"ESM1b_ts_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","\n","    # To avoid process on duplicate params\n","    processed_params = []\n","    for iteration in range(START, TOTAL_ITERATION):\n","        print(f\"Iteration-{iteration}...\")\n","        # randomly select the params from params space\n","        params = {\n","            key: np.random.choice(value) for key, value in PARAM_SPACE.items()\n","            }\n","\n","        if (iteration < START) or (params in processed_params) or is_not_require_params(params):\n","            continue\n","\n","        model = create_model(n_timesteps, n_features, **params)\n","        model = train_model(model, train_X, train_Y, test_X, test_Y, params)\n","        y_pred = model.predict(test_X).reshape(-1)\n","        curr_r2 = round(r2_score(test_Y, y_pred), 2)\n","\n","        if curr_r2 > BEST_R2:\n","            BEST_R2 = curr_r2\n","            BEST_HYPER_PARAMS = params\n","\n","            # delete_file(BEST_MODEL)\n","            # delete_file(BEST_HYPER_PARAMS_FILE)\n","\n","            save_best_params(BEST_HYPER_PARAMS_FILE, BEST_HYPER_PARAMS, BEST_R2)\n","            save_model(model, BEST_MODEL)\n","            print(f\"New best R2 score: {BEST_R2}\")\n","            print(f\"New Best hyperparameters: {BEST_HYPER_PARAMS}\")\n","\n","        processed_params.append(params)\n"]},{"cell_type":"markdown","metadata":{"id":"CiIkgb6E9asr"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300942,"status":"ok","timestamp":1712993805590,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"oZebAIQ09bsd","outputId":"763b7c6a-0513-416a-b573-cc09c78d7395"},"outputs":[{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 5ms/step\n","Model-1 results {'mse': 0.56, 'R2 score': 0.42, 'pearson coefficient': 0.64}\n","28/28 [==============================] - 0s 4ms/step\n","Model-2 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.64}\n","28/28 [==============================] - 0s 4ms/step\n","Model-3 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","28/28 [==============================] - 0s 3ms/step\n","Model-4 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","28/28 [==============================] - 0s 3ms/step\n","Model-5 results {'mse': 0.57, 'R2 score': 0.4, 'pearson coefficient': 0.63}\n","ensemble output: {'mse': 0.56, 'R2 score': 0.42, 'pearson coefficient': 0.64}\n"]}],"source":["MODEL_DIR = \"../../models/train_models/\"\n","TOTAL_MODELS = 5\n","\n","# Trained hyperparameter\n","'''\n","HYPER_PARAMS = {\n","    \"filters_1\": 14,\n","    \"filters_2\": 24,\n","    \"filters_3\": 24,\n","    \"kernel_size_1\": 15,\n","    \"kernel_size_2\": 7,\n","    \"kernel_size_3\": 9,\n","    \"dense_units_1\": 512,\n","    \"dense_units_2\": 128,\n","    \"dropout_rate\": 0.3,\n","    \"optimizer\": \"rmsprop\",\n","    \"batch_size\": 8,\n","}\n","\n","HYPER_PARAMS = {\n","    'filters_1': 14,\n","    'filters_2': 16,\n","    'filters_3': 28,\n","    'kernel_size_1': 13,\n","    'kernel_size_2': 11,\n","    'kernel_size_3': 13,\n","    'dense_units_1': 512,\n","    'dense_units_2': 8,\n","    'dropout_rate': 0.3,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 24}\n","\n","'''\n","HYPER_PARAMS = {\n","    'filters_1': 4,\n","    'filters_2': 14,\n","    'filters_3': 16,\n","    'kernel_size_1': 13,\n","    'kernel_size_2': 9,\n","    'kernel_size_3': 11,\n","    'dense_units_1': 512,\n","    'dense_units_2': 128,\n","    'dropout_rate': 0.3,\n","    'optimizer': 'rmsprop',\n","    'batch_size': 8\n","    }\n","\n","if __name__ == \"__main__\":\n","    # apply processing on train and test dataset\n","    train_X, train_Y = get_processed_data([data_train[\"structural_fp\"],\n","                                          data_train[\"ESM1b_ts_norm\"]],\n","                                          data_train[\"log10_kcat_norm\"])\n","\n","    test_X, test_Y = get_processed_data([data_test[\"structural_fp\"],\n","                                        data_test[\"ESM1b_ts_norm\"]],\n","                                        data_test[\"log10_kcat_norm\"])\n","\n","    n_timesteps, n_features = train_X.shape[1], train_X.shape[2]\n","    # getting the CNN model architecture\n","    model = create_model(n_timesteps, n_features, **HYPER_PARAMS)\n","    # train and get model preds\n","    model_preds = get_model_preds(MODEL_DIR, HYPER_PARAMS, TOTAL_MODELS,\n","                                  model, train_X, train_Y, test_X, test_Y)\n","    # calculate weighted mean model predicts\n","    weighted_avg_pred = calculate_weighted_mean(model_preds, test_Y)\n","    # output preds\n","    print(f\"ensemble output: {evaluate_model(weighted_avg_pred, test_Y)}\")\n","\n","    esm1b_ts_struct_weighted_pred = weighted_avg_pred\n"]},{"cell_type":"markdown","metadata":{"id":"dXEuCv_Hw6Gw"},"source":["# ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1712993805591,"user":{"displayName":"M Faizan","userId":"01979528019072830709"},"user_tz":-300},"id":"WC90_5JqzWPy","outputId":"70cd8dea-55db-4792-81c2-9d3b93b4608a"},"outputs":[{"output_type":"stream","name":"stdout","text":["ensemble output: {'mse': 0.44, 'R2 score': 0.53, 'pearson coefficient': 0.73}\n"]}],"source":["combined_weighted_preds = np.array([\n","    esm1b_drfp_weighted_pred,\n","    esm1b_diff_weighted_pred,\n","    esm1b_ts_drfp_weighted_pred,\n","    esm1b_ts_diff_weighted_pred,\n","    esm1b_struct_weighted_pred,\n","    esm1b_ts_struct_weighted_pred\n","    ])\n","\n","weighted_avg_pred = calculate_weighted_mean(combined_weighted_preds, test_Y)\n","print(f\"ensemble output: {evaluate_model(weighted_avg_pred, test_Y)}\")"]},{"cell_type":"markdown","metadata":{"id":"98rTjQvJUgPO"},"source":["ensemble output: {'mse': 0.44, 'R2 score': 0.54, 'pearson coefficient': 0.73}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXO2_m-_KsEX"},"outputs":[],"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["V3qa1i7Er8kz","Jdi0gDZvr8k2"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}